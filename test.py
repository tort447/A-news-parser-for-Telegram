import asyncio
import requests
import os
import time
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher
from aiogram.types import Message
from aiogram.filters import Command
import logging
from deep_translator import GoogleTranslator, exceptions

# üîπ –¢–æ–∫–µ–Ω –±–æ—Ç–∞ —Ç–∞ ID –∫–∞–Ω–∞–ª—ñ–≤
BOT_TOKEN = "5367470824:AAHQtKIOCVnq7a74UnNwiMqIQQ6jXL-Evuc"
CHANNEL_UA = "-1002080353500"
CHANNEL_RU = "-1002080353500"  # –í—Å—Ç–∞–≤–∏—Ç–∏ ID —Ä–æ—Å—ñ–π—Å—å–∫–æ–≥–æ –∫–∞–Ω–∞–ª—É

# üîπ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–æ—Ç–∞
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot=bot)

# üîπ URL —Å–∞–π—Ç—É –¢–°–ù
MAIN_NEWS_URL = "https://tsn.ua/"

# üîπ –õ–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(filename="bot.log", level=logging.INFO,
                    format="%(asctime)s - %(message)s")

# üîπ –§–∞–π–ª –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–∂–µ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–∏—Ö –Ω–æ–≤–∏–Ω
SENT_NEWS_FILE = "sent_news.txt"

# üîπ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–µ—Ä–µ–∫–ª–∞–¥–∞—á–∞
translator = GoogleTranslator(source="uk", target="ru")

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∂–µ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤


def load_sent_news():
    if not os.path.exists(SENT_NEWS_FILE):
        return set()
    with open(SENT_NEWS_FILE, "r", encoding="utf-8") as file:
        return set(line.strip() for line in file.readlines())

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ —É —Ñ–∞–π–ª


def save_sent_news(title):
    with open(SENT_NEWS_FILE, "a", encoding="utf-8") as file:
        file.write(title + "\n")

# üîπ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –û–°–¢–ê–ù–ù–Ü–• –ü–û–°–ò–õ–ê–ù–¨ –ù–ê –ù–û–í–ò–ù–ò


def get_latest_news_links():
    response = requests.get(MAIN_NEWS_URL)
    soup = BeautifulSoup(response.content, "html.parser")

    news_links = []
    seen_titles = set()
    for article in soup.find_all("article"):
        title_tag = article.find("a", class_="c-card__link")
        if title_tag:
            title = title_tag.get_text(strip=True)
            link = title_tag["href"]
            if not link.startswith("http"):
                link = "https://tsn.ua" + link

            if title not in seen_titles:
                seen_titles.add(title)
                news_links.append({"title": title, "link": link})

    return news_links[:5]

# üîπ –û—á–∏—â–µ–Ω–Ω—è —Ç–∞ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –Ω–æ–≤–∏–Ω–∏


def clean_text(text):
    # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ —Ñ—Ä–∞–∑–∏
    remove_phrases = [
        "–†–µ–∫–ª–∞–º–∞", "–¥–æ–ø–æ–≤–Ω—é—î—Ç—å—Å—è", "–ü—Ä–æ —Ü–µ –ø–æ–≤—ñ–¥–æ–º–∏–ª–∏", "–ù–∞–≥–∞–¥–∞—î–º–æ",
        "–Ø–∫ –ø–æ–≤—ñ–¥–æ–º–ª—è—î", "–ó–∞ –¥–∞–Ω–∏–º–∏", "–ó–∞–∑–Ω–∞—á–∞—î—Ç—å—Å—è", "–Ø–∫ –∑–∞–∑–Ω–∞—á–∏–ª–∏ –≤",
        "–¢–∞–∫–æ–∂", "–í–æ–¥–Ω–æ—á–∞—Å", "–¢–°–ù.ua", "–ß–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–æ–∂", "–©–æ –≤—ñ–¥–æ–º–æ?",
        "–ü—ñ–¥–ø–∏—Å—É–π—Ç–µ—Å—å –Ω–∞ –Ω–∞—à—ñ –∫–∞–Ω–∞–ª–∏ —É Telegram —Ç–∞ Viber.", "–ü—ñ–¥–ø–∏—Å—É–π—Ç–µ—Å—å –Ω–∞ –Ω–∞—à—ñ –∫–∞–Ω–∞–ª–∏ —ÉTelegram—Ç–∞Viber."
    ]
    for phrase in remove_phrases:
        text = text.replace(phrase, "")

    # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏
    text = text.replace("  ", " ").strip()

    # –í–∏–¥–∞–ª—è—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ –∞–±–∑–∞—Ü–∏ —Ç–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏
    paragraphs = text.split("\n\n")
    cleaned_paragraphs = []
    seen_sentences = set()

    for para in paragraphs:
        para = para.strip()

        # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –∫–æ–º–∏ –Ω–∞ –ø–æ—á–∞—Ç–∫—É —Ä–µ—á–µ–Ω–Ω—è
        if para.startswith(", "):
            para = para[2:]

        # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ —Ä–µ—á–µ–Ω–Ω—è —Ç–∏–ø—É ": "
        if para.endswith(":"):
            continue

        # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∞–±–∑–∞—Ü—ñ–≤
        if para not in seen_sentences:
            seen_sentences.add(para)
            cleaned_paragraphs.append(para)

    return "\n\n".join(cleaned_paragraphs)
# üîπ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ü–û–í–ù–û–ì–û –¢–ï–ö–°–¢–£ –ù–û–í–ò–ù–ò + –ì–û–õ–û–í–ù–û–ì–û –§–û–¢–û


def get_news_content(news_url):
    response = requests.get(news_url)
    soup = BeautifulSoup(response.content, "html.parser")

    content_tag = soup.find("div", class_="c-article__body")
    if content_tag:
        content_paragraphs = [p.get_text(strip=True) for p in content_tag.find_all(
            "p") if p.get_text(strip=True)]
        content = "\n\n".join(content_paragraphs)
    else:
        content = "–û–ø–∏—Å –Ω–æ–≤–∏–Ω–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π."

    # –û—á–∏—â—É—î–º–æ —Ç–µ–∫—Å—Ç
    content = clean_text(content)

    # –û–±—Ä—ñ–∑–∞—î–º–æ —Ç–µ–∫—Å—Ç, —è–∫—â–æ –≤—ñ–Ω –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π
    if len(content) > 4090:
        content = content[:4090] + "..."

    # –û—Ç—Ä–∏–º—É—î–º–æ –≥–æ–ª–æ–≤–Ω–µ —Ñ–æ—Ç–æ –Ω–æ–≤–∏–Ω–∏ (meta og:image)
    image_url = None
    meta_image = soup.find("meta", property="og:image")
    if meta_image:
        image_url = meta_image["content"]

    return content, image_url

# üîπ –ü–µ—Ä–µ–∫–ª–∞–¥ —Ç–µ–∫—Å—Ç—É –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É


def translate_to_russian(text, attempts=3):
    paragraphs = text.split("\n\n")
    translated_paragraphs = []

    for para in paragraphs:
        for _ in range(attempts):
            try:
                translation = translator.translate(para)
                if translation is None:
                    raise ValueError("–ü–µ—Ä–µ–∫–ª–∞–¥ –ø–æ–≤–µ—Ä–Ω—É–≤ None")
                translated_paragraphs.append(translation)
                break
            except (exceptions.RequestError, ValueError):
                time.sleep(2)
        else:
            # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏, –∑–∞–ª–∏—à–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª
            translated_paragraphs.append(para)

    return "\n\n".join(translated_paragraphs)

# üîπ –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–∏–Ω —É Telegram-–∫–∞–Ω–∞–ª–∏


async def send_news_to_channels():
    sent_news = load_sent_news()
    news_list = get_latest_news_links()
    seen_titles = set()

    for news in news_list:
        title, link = news["title"], news["link"]

        if title in sent_news or title in seen_titles:
            continue

        seen_titles.add(title)

        # –û—Ç—Ä–∏–º—É—î–º–æ –ø–æ–≤–Ω–∏–π –æ–ø–∏—Å –Ω–æ–≤–∏–Ω–∏ —Ç–∞ —Ñ–æ—Ç–æ
        description, image_url = get_news_content(link)

        # üîπ –§–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
        message_text_ua = f"üì∞ <b>{
            title}</b>\n\n{description}\n\nüîó <a href='{link}'>–ß–∏—Ç–∞—Ç–∏ –¥–∞–ª—ñ</a>"

        # üîπ –ü–µ—Ä–µ–∫–ª–∞–¥ —Ä–æ—Å—ñ–π—Å—å–∫–æ—é
        title_ru = translate_to_russian(title)
        description_ru = translate_to_russian(description)
        message_text_ru = f"üì∞ <b>{
            title_ru}</b>\n\n{description_ru}\n\nüîó <a href='{link}'>–ü–æ–¥—Ä–æ–±–Ω–µ–µ</a>"

        async def send_news(channel, text, img):
            try:
                if img:
                    await bot.send_photo(channel, photo=img)
                await bot.send_message(channel, text[:4096], parse_mode="HTML", disable_web_page_preview=True)
            except Exception as e:
                logging.error(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ —É {channel}: {str(e)}")

        await send_news(CHANNEL_UA, message_text_ua, image_url)
        await send_news(CHANNEL_RU, message_text_ru, image_url)

        logging.info(f"‚úÖ –û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ: {title} (UA) —Ç–∞ {title_ru} (RU)")
        save_sent_news(title)

# üîπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∑–∞–ø—É—Å–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–æ–≤–∏–Ω –∫–æ–∂–Ω—ñ 10 —Ö–≤–∏–ª–∏–Ω


async def auto_news_scheduler():
    while True:
        await send_news_to_channels()
        await asyncio.sleep(1)

# üîπ –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É


async def main():
    asyncio.create_task(auto_news_scheduler())
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
